#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Hugging Face Hub ìë™ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import torch
from pathlib import Path
from huggingface_hub import HfApi, create_repo, upload_file, upload_folder

# ìƒìœ„ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent / "intelligent-tokenizer_v6.0"))

def upload_to_huggingface(
    repo_name="intelligent-tokenizer-v6",
    organization=None,  # Noneì´ë©´ ê°œì¸ ê³„ì •
    private=False
):
    """Hugging Face Hubì— ëª¨ë¸ ì—…ë¡œë“œ"""
    
    print("ğŸš€ Hugging Face Hub ì—…ë¡œë“œ ì‹œì‘...")
    
    # 1. API ì´ˆê¸°í™”
    api = HfApi()
    
    # 2. Repository ì´ë¦„ ì„¤ì •
    if organization:
        repo_id = f"{organization}/{repo_name}"
    else:
        repo_id = repo_name  # ê°œì¸ ê³„ì •ì€ usernameì´ ìë™ìœ¼ë¡œ ë¶™ìŒ
    
    try:
        # 3. Repository ìƒì„±
        print(f"ğŸ“¦ Creating repository: {repo_id}")
        create_repo(
            repo_id=repo_id,
            repo_type="model",
            private=private,
            exist_ok=True
        )
        print("âœ… Repository created/verified")
        
        # 4. ì²´í¬í¬ì¸íŠ¸ë¥¼ PyTorch í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        checkpoint_path = Path("../intelligent-tokenizer_v6.0/checkpoints/unified/latest_checkpoint.pt")
        if checkpoint_path.exists():
            print("ğŸ”„ Converting checkpoint to Hugging Face format...")
            
            checkpoint = torch.load(checkpoint_path, map_location="cpu", weights_only=False)
            
            # ëª¨ë¸ state_dictë§Œ ì €ì¥
            torch.save(
                checkpoint['model_state_dict'],
                "pytorch_model.bin"
            )
            print("âœ… pytorch_model.bin created")
            
            # Training state ì €ì¥ (ì„ íƒì‚¬í•­)
            training_state = {
                "epoch": checkpoint['epoch'],
                "loss": checkpoint['loss'],
                "model_config": checkpoint['model_config']
            }
            torch.save(training_state, "training_state.bin")
            print("âœ… training_state.bin created")
        
        # 5. íŒŒì¼ ì—…ë¡œë“œ
        files_to_upload = [
            "README.md",
            "config.json",
            "tokenizer_config.json",
            "pytorch_model.bin",
            "training_state.bin",
            "requirements.txt",
            ".gitattributes"
        ]
        
        print("\nğŸ“¤ Uploading files...")
        for file in files_to_upload:
            if Path(file).exists():
                print(f"  Uploading {file}...")
                upload_file(
                    path_or_fileobj=file,
                    path_in_repo=file,
                    repo_id=repo_id,
                    repo_type="model"
                )
                print(f"  âœ… {file} uploaded")
            else:
                print(f"  âš ï¸ {file} not found, skipping...")
        
        # 6. ì†ŒìŠ¤ ì½”ë“œ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)
        src_files = {
            "../intelligent-tokenizer_v6.0/src/core/byte_tokenizer_v6.py": "byte_tokenizer_v6.py",
            "../intelligent-tokenizer_v6.0/core/boundary_aware_model.py": "boundary_aware_model.py",
        }
        
        print("\nğŸ“¤ Uploading source code...")
        for src, dst in src_files.items():
            src_path = Path(src)
            if src_path.exists():
                print(f"  Uploading {dst}...")
                upload_file(
                    path_or_fileobj=str(src_path),
                    path_in_repo=dst,
                    repo_id=repo_id,
                    repo_type="model"
                )
                print(f"  âœ… {dst} uploaded")
        
        print("\n" + "="*60)
        print("ğŸ‰ ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ”— Model URL: https://huggingface.co/{repo_id}")
        print("="*60)
        
        # 7. ì‚¬ìš© ë°©ë²• ì¶œë ¥
        print("\nğŸ“– ì‚¬ìš© ë°©ë²•:")
        print("```python")
        print(f"from transformers import AutoModel")
        print(f"model = AutoModel.from_pretrained('{repo_id}', trust_remote_code=True)")
        print("```")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. huggingface-cli login ì‹¤í–‰")
        print("2. https://huggingface.co/settings/tokens ì—ì„œ í† í° ìƒì„±")
        print("3. Write ê¶Œí•œ í•„ìš”")

if __name__ == "__main__":
    # ë¨¼ì € êµ¬ì¡° ì¤€ë¹„
    print("ğŸ“ Preparing Hugging Face structure...")
    os.system("python prepare_huggingface.py")
    
    print("\n" + "="*60)
    print("âš ï¸ ì—…ë¡œë“œ ì „ í™•ì¸ì‚¬í•­:")
    print("1. Hugging Face ê³„ì •ì´ ìˆë‚˜ìš”?")
    print("2. huggingface-cli login í–ˆë‚˜ìš”?")
    print("3. ê³µê°œ(public) í• ê±´ê°€ìš”? ë¹„ê³µê°œ(private)?")
    print("="*60)
    
    # ì‚¬ìš©ì ì…ë ¥
    response = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if response.lower() == 'y':
        username = input("Hugging Face username (ë˜ëŠ” organization): ")
        private = input("Private repository? (y/n): ").lower() == 'y'
        
        upload_to_huggingface(
            repo_name="intelligent-tokenizer-v6",
            organization=username if username else None,
            private=private
        )
    else:
        print("ğŸ“ ìˆ˜ë™ ì—…ë¡œë“œ ë°©ë²•:")
        print("1. https://huggingface.co/new ì—ì„œ ëª¨ë¸ ìƒì„±")
        print("2. git clone https://huggingface.co/username/model-name")
        print("3. íŒŒì¼ ë³µì‚¬ í›„ git push")